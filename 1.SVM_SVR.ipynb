{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfz6JI8rrRl0",
        "outputId": "16e9c857-c675-4edf-dace-55f99d77688c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.5690\n",
            "Epoch [20/100], Loss: 0.4954\n",
            "Epoch [30/100], Loss: 0.4410\n",
            "Epoch [40/100], Loss: 0.4087\n",
            "Epoch [50/100], Loss: 0.3847\n",
            "Epoch [60/100], Loss: 0.3681\n",
            "Epoch [70/100], Loss: 0.3570\n",
            "Epoch [80/100], Loss: 0.3482\n",
            "Epoch [90/100], Loss: 0.3414\n",
            "Epoch [100/100], Loss: 0.3358\n",
            "Test Accuracy: 88.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=500, n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=42)\n",
        "y = 2 * y - 1  # Convert labels from (0,1) to (-1,1)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Define the SVM as a simple linear model\n",
        "class SVM_NN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SVM_NN, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # Linear transformation\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)  # No activation function\n",
        "\n",
        "# Hinge loss function\n",
        "def hinge_loss(output, target):\n",
        "    return torch.mean(torch.clamp(1 - target * output, min=0))  # max(0, 1 - y * (w^T x + b))\n",
        "\n",
        "# Initialize model, optimizer\n",
        "model = SVM_NN(input_dim=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "lambda_reg = 0.01  # Regularization term\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(X_train_tensor)\n",
        "    loss = hinge_loss(output, y_train_tensor) + lambda_reg * torch.norm(model.linear.weight, p=2)  # Hinge loss + L2 regularization\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor).sign().numpy()\n",
        "    accuracy = np.mean(y_pred == y_test.reshape(-1, 1))\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic data (same as before)\n",
        "np.random.seed(42)\n",
        "X = np.sort(5 * np.random.rand(100, 1), axis=0)  # Features (1D)\n",
        "y = np.sin(X).ravel() + 0.1 * np.random.randn(100)  # Target with noise\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # Keep in original scale for evaluation\n",
        "\n",
        "# Define SVR-like Neural Network\n",
        "class SVR_NN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SVR_NN, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # Simple linear regression layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# SVR Loss (Îµ-insensitive loss)\n",
        "class SVRLoss(nn.Module):\n",
        "    def __init__(self, epsilon=0.1, lambda_reg=0.01):\n",
        "        super(SVRLoss, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, predictions, targets, model):\n",
        "        abs_error = torch.abs(predictions - targets)\n",
        "        loss = torch.mean(torch.clamp(abs_error - self.epsilon, min=0))  # Max(0, |y - f(X)| - epsilon)\n",
        "        reg = self.lambda_reg * torch.norm(model.linear.weight, p=2)  # L2 regularization\n",
        "        return loss + reg\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "model = SVR_NN(input_dim=1)\n",
        "criterion = SVRLoss(epsilon=0.1, lambda_reg=0.01)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(X_train_tensor)\n",
        "    loss = criterion(predictions, y_train_tensor, model)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate on test data\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test_tensor).numpy()\n",
        "    y_pred = scaler_y.inverse_transform(y_pred_scaled)  # Convert back to original scale\n",
        "    mse = mean_squared_error(y_test,y_pred)\n",
        "    print(f\"mse: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u80_6BVcrYFR",
        "outputId": "79b8713f-5de5-45ed-adf3-204fd5c45bc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.7175\n",
            "Epoch [20/100], Loss: 0.6451\n",
            "Epoch [30/100], Loss: 0.5921\n",
            "Epoch [40/100], Loss: 0.5532\n",
            "Epoch [50/100], Loss: 0.5236\n",
            "Epoch [60/100], Loss: 0.4973\n",
            "Epoch [70/100], Loss: 0.4743\n",
            "Epoch [80/100], Loss: 0.4555\n",
            "Epoch [90/100], Loss: 0.4411\n",
            "Epoch [100/100], Loss: 0.4299\n",
            "mse: 0.2233\n"
          ]
        }
      ]
    }
  ]
}